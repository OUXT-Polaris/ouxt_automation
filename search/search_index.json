{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"OUXT Polaris Development Automation Tool \u2693\ufe0e Status Badge \u2693\ufe0e Build Test \u2693\ufe0e Automation \u2693\ufe0e What is this? \u2693\ufe0e This tool supports to build our software and deploy them into local_machine and real robot. This tool works on ansible and github actions Contents Guide \u2693\ufe0e If you want to know how to setup development in your local machine. \u2693\ufe0e See tutorials If you want to see navigation demo in your local machine. \u2693\ufe0e See tutorials If you want to know how to use tools. \u2693\ufe0e See tools If you want to know hardware specification. \u2693\ufe0e See hardware documenation If you want to know how our CI/CD pipeline works. \u2693\ufe0e See automation pipelines documentation","title":"Home"},{"location":"#ouxt-polaris-development-automation-tool","text":"","title":"OUXT Polaris Development Automation Tool"},{"location":"#status-badge","text":"","title":"Status Badge"},{"location":"#what-is-this","text":"This tool supports to build our software and deploy them into local_machine and real robot. This tool works on ansible and github actions","title":"What is this?"},{"location":"#contents-guide","text":"","title":"Contents Guide"},{"location":"automation_pipeline/","text":"Automation Pipeline \u2693\ufe0e Repository Architecture \u2693\ufe0e OUXT-Polaris softwares are separeated in many repositories in order to run continuous integration quickly. So, we developing integration pipeline for operating complex software stacks and deploy it. Integration Pipeline \u2693\ufe0e Integration pipeline is deployed at github actions in each repositories. Actions in ouxt_automation package \u2693\ufe0e You can see the status of all Actions here . ansible \u2693\ufe0e graph TB pull_request --send --> ouxt_automation developer --manual hook--> ouxt_automation daily_hook --> ouxt_automation linkStyle 0 stroke-width:2px,stroke:blue; linkStyle 1 stroke-width:2px,stroke:blue; linkStyle 2 stroke-width:2px,stroke:blue; click ansible \"https://github.com/OUXT-Polaris/ouxt_automation\" \"ouxt_automation repository\" run_ansible job runs ansible with setup-full playbook and check the setup tool works well. graph TB pull_request --send --> ouxt_automation developer --manual hook--> ouxt_automation daily_hook --> ouxt_automation linkStyle 0 stroke-width:2px,stroke:blue; linkStyle 1 stroke-width:2px,stroke:blue; linkStyle 2 stroke-width:2px,stroke:blue; click ouxt_automation \"https://github.com/OUXT-Polaris/ouxt_automation\" \"ouxt_automation repository\" run_ansible_with_docker job runs ansible with setup-docker playbook and check the setup tool works well with docker. document \u2693\ufe0e graph TB pull_request --send -->ouxt_automation developer --manual hook-->ouxt_automation daily_hook --> ouxt_automation pull_request -- merged -->ouxt_automation ouxt_automation -- deploy --> github_pages linkStyle 0 stroke-width:2px,stroke:blue; linkStyle 1 stroke-width:2px,stroke:red; linkStyle 2 stroke-width:2px,stroke:red; linkStyle 3 stroke-width:2px,stroke:red; linkStyle 4 stroke-width:2px,stroke:red; click ouxt_automation \"https://github.com/OUXT-Polaris/ouxt_automation\" \"ouxt_automation repository\" click github_pages \"https://ouxt-polaris.github.io/ouxt_automation/\" \"github pages\" documentation workflow generate this documentation site and deploy it into github pages. deploy_workflow \u2693\ufe0e graph TB developer --manual hook-->ouxt_automation daily_hook --> ouxt_automation ouxt_automation -- deploy workflow --> target_repository linkStyle 0 stroke-width:2px,stroke:blue; linkStyle 1 stroke-width:2px,stroke:blue; linkStyle 2 stroke-width:2px,stroke:blue; click ouxt_automation \"https://github.com/OUXT-Polaris/ouxt_automation\" \"ouxt_automation repository\" deploy_workflow helps maintainers to deploy and maintain workflows for each pacakges. currently, over 25 packages are maintained by this workflow. check_workflow_deployment \u2693\ufe0e graph TB developer --manual hook-->ouxt_automation daily_hook --> ouxt_automation ouxt_automation -- check workflow exists --> target_repository ouxt_automation -- if workflow does not exist --> slack ouxt_automation -- request repos file --> artifact artifact -- send repos file --> ouxt_automation linkStyle 0 stroke-width:2px,stroke:blue; linkStyle 1 stroke-width:2px,stroke:blue; linkStyle 2 stroke-width:2px,stroke:blue; linkStyle 3 stroke-width:2px,stroke:blue; linkStyle 4 stroke-width:2px,stroke:blue; linkStyle 5 stroke-width:2px,stroke:blue; click ouxt_automation \"https://github.com/OUXT-Polaris/ouxt_automation\" \"ouxt_automation repository\" check_workflow_deployment workflow checks github repositories in downloaded repos file and if the requred workflow does not exist in the target repository, notify this infomation to the team slack. Actions in each repositories \u2693\ufe0e In each repository, pull requests automatically runs build tests, unit tests and scenario test.","title":"Automation Pipeline"},{"location":"automation_pipeline/#automation-pipeline","text":"","title":"Automation Pipeline"},{"location":"automation_pipeline/#repository-architecture","text":"OUXT-Polaris softwares are separeated in many repositories in order to run continuous integration quickly. So, we developing integration pipeline for operating complex software stacks and deploy it.","title":"Repository Architecture"},{"location":"automation_pipeline/#integration-pipeline","text":"Integration pipeline is deployed at github actions in each repositories.","title":"Integration Pipeline"},{"location":"automation_pipeline/#actions-in-ouxt_automation-package","text":"You can see the status of all Actions here .","title":"Actions in ouxt_automation package"},{"location":"automation_pipeline/#actions-in-each-repositories","text":"In each repository, pull requests automatically runs build tests, unit tests and scenario test.","title":"Actions in each repositories"},{"location":"license/","text":"This tool provides under Apache 2.0 license. Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION 1. Definitions. \"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License. \"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\" \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. 2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. 3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. 4. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. 5. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. 6. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. 7. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. 8. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. 9. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets \"[]\" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives. Copyright [yyyy] [name of copyright owner] Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"LICENSE"},{"location":"packages/","text":"Software Packages \u2693\ufe0e dashboard \u2693\ufe0e BuildTest Release UpdateDashboard Documentation OUXT-Polaris/color_names nan OUXT-Polaris/data_buffer nan OUXT-Polaris/dynamixel_hardware_interface OUXT-Polaris/geographic_conversion nan nan OUXT-Polaris/geographic_info nan nan OUXT-Polaris/geometry_msgs_data_buffer nan nan OUXT-Polaris/hermite_path_planner nan OUXT-Polaris/image_processing_utils nan nan OUXT-Polaris/joy_to_twist nan OUXT-Polaris/lua_vendor nan nan OUXT-Polaris/message_synchronizer nan OUXT-Polaris/miniv_control nan nan OUXT-Polaris/miniv_description nan nan OUXT-Polaris/navi_sim nan OUXT-Polaris/nmea_gps_driver OUXT-Polaris/nmea_hardware_interface nan OUXT-Polaris/nmea_to_geopose nan OUXT-Polaris/odom_frame_publisher nan nan OUXT-Polaris/ouxt_common nan OUXT-Polaris/pcl_apps nan OUXT-Polaris/perception_bringup nan OUXT-Polaris/playstation_controller_drivers nan OUXT-Polaris/quaternion_operation nan nan OUXT-Polaris/robotx_behavior_tree nan nan OUXT-Polaris/robotx_communication nan nan OUXT-Polaris/robotx_costmap_calculator nan nan OUXT-Polaris/robotx_ekf nan OUXT-Polaris/scan_segmentation nan OUXT-Polaris/sol_vendor nan nan OUXT-Polaris/tcp_sender nan nan OUXT-Polaris/usv_controller nan 0 OUXT-Polaris/dynamixel_hardware_interface prepare humble OUXT-Polaris/geographic_info [Bot] Update workflow OUXT-Polaris/geometry_msgs_data_buffer [Bot] Update workflow OUXT-Polaris/image_processing_utils [Bot] Update workflow OUXT-Polaris/lua_vendor [Bot] Update workflow OUXT-Polaris/miniv_control prepare humble OUXT-Polaris/navi_sim Feature/navi simulator OUXT-Polaris/nmea_hardware_interface prepare humble OUXT-Polaris/perception_bringup update depends OUXT-Polaris/robotx_behavior_tree first commit for goaroundwaypoints OUXT-Polaris/usv_controller Feature/velocity controller","title":"Software Packages"},{"location":"packages/#software-packages","text":"","title":"Software Packages"},{"location":"packages/#dashboard","text":"BuildTest Release UpdateDashboard Documentation OUXT-Polaris/color_names nan OUXT-Polaris/data_buffer nan OUXT-Polaris/dynamixel_hardware_interface OUXT-Polaris/geographic_conversion nan nan OUXT-Polaris/geographic_info nan nan OUXT-Polaris/geometry_msgs_data_buffer nan nan OUXT-Polaris/hermite_path_planner nan OUXT-Polaris/image_processing_utils nan nan OUXT-Polaris/joy_to_twist nan OUXT-Polaris/lua_vendor nan nan OUXT-Polaris/message_synchronizer nan OUXT-Polaris/miniv_control nan nan OUXT-Polaris/miniv_description nan nan OUXT-Polaris/navi_sim nan OUXT-Polaris/nmea_gps_driver OUXT-Polaris/nmea_hardware_interface nan OUXT-Polaris/nmea_to_geopose nan OUXT-Polaris/odom_frame_publisher nan nan OUXT-Polaris/ouxt_common nan OUXT-Polaris/pcl_apps nan OUXT-Polaris/perception_bringup nan OUXT-Polaris/playstation_controller_drivers nan OUXT-Polaris/quaternion_operation nan nan OUXT-Polaris/robotx_behavior_tree nan nan OUXT-Polaris/robotx_communication nan nan OUXT-Polaris/robotx_costmap_calculator nan nan OUXT-Polaris/robotx_ekf nan OUXT-Polaris/scan_segmentation nan OUXT-Polaris/sol_vendor nan nan OUXT-Polaris/tcp_sender nan nan OUXT-Polaris/usv_controller nan 0 OUXT-Polaris/dynamixel_hardware_interface prepare humble OUXT-Polaris/geographic_info [Bot] Update workflow OUXT-Polaris/geometry_msgs_data_buffer [Bot] Update workflow OUXT-Polaris/image_processing_utils [Bot] Update workflow OUXT-Polaris/lua_vendor [Bot] Update workflow OUXT-Polaris/miniv_control prepare humble OUXT-Polaris/navi_sim Feature/navi simulator OUXT-Polaris/nmea_hardware_interface prepare humble OUXT-Polaris/perception_bringup update depends OUXT-Polaris/robotx_behavior_tree first commit for goaroundwaypoints OUXT-Polaris/usv_controller Feature/velocity controller","title":"dashboard"},{"location":"tools/tools/","text":"Tools \u2693\ufe0e Train yolox model \u2693\ufe0e Requirement \u2693\ufe0e docker docker-compose nvidia-docker2 nvidia-gpu (hardware) cd docker/train_yolox/checkpoints wget https://github.com/Megvii-BaseDetection/YOLOX/releases/download/0.1.1rc0/yolox_s.pth cd ../datasets download datasets via this link . docker-compose up --build While training, you can see output like below. 100%|##########| 1/1 [00:00<00:00, 4.69it/s] train_yolox_container | Running per image evaluation... train_yolox_container | Evaluate annotation type *bbox* train_yolox_container | COCOeval_opt.evaluate() finished in 0.01 seconds. train_yolox_container | Accumulating evaluation results... train_yolox_container | 2022-06-03 04:51:11 | INFO | pycocotools.coco:366 - index created! train_yolox_container | 2022-06-03 04:51:11 | INFO | yolox.core.trainer:342 - train_yolox_container | Average forward time: 0.00 ms, Average NMS time: 0.00 ms, Average inference time: 0.00 ms train_yolox_container | Average Precision (AP) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.000 train_yolox_container | Average Precision (AP) @[ IoU=0.50 | area= all | maxDets=100 ] = 0.000 train_yolox_container | Average Precision (AP) @[ IoU=0.75 | area= all | maxDets=100 ] = 0.000 train_yolox_container | Average Precision (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000 train_yolox_container | Average Precision (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000 train_yolox_container | Average Precision (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000 train_yolox_container | Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 1 ] = 0.000 train_yolox_container | Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 10 ] = 0.000 train_yolox_container | Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.000 train_yolox_container | Average Recall (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000 train_yolox_container | Average Recall (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000 train_yolox_container | Average Recall (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000 train_yolox_container | train_yolox_container | 2022-06-03 04:51:11 | INFO | yolox.core.trainer:352 - Save weights to ./YOLOX_outputs/yolox_s train_yolox_container | 2022-06-03 04:51:11 | INFO | yolox.core.trainer:352 - Save weights to ./YOLOX_outputs/yolox_s train_yolox_container | 2022-06-03 04:51:12 | INFO | yolox.core.trainer:203 - ---> start train epoch272 train_yolox_container | 2022-06-03 04:51:15 | INFO | yolox.core.trainer:352 - Save weights to ./YOLOX_outputs/yolox_s train_yolox_container | 2022-06-03 04:51:15 | INFO | yolox.evaluators.coco_evaluator:235 - Evaluate in main process... train_yolox_container | 2022-06-03 04:51:15 | INFO | yolox.evaluators.coco_evaluator:268 - Loading and preparing results... train_yolox_container | 2022-06-03 04:51:15 | INFO | yolox.evaluators.coco_evaluator:268 - DONE (t=0.00s) train_yolox_container | 2022-06-03 04:51:15 | INFO | pycocotools.coco:366 - creating index... train_yolox_container | 2022-06-03 04:51:15 | INFO | pycocotools.coco:366 - index created! train_yolox_container | 2022-06-03 04:51:16 | INFO | yolox.core.trainer:342 - train_yolox_container | Average forward time: 0.00 ms, Average NMS time: 0.00 ms, Average inference time: 0.00 ms train_yolox_container | Average Precision (AP) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.000 train_yolox_container | Average Precision (AP) @[ IoU=0.50 | area= all | maxDets=100 ] = 0.000 train_yolox_container | Average Precision (AP) @[ IoU=0.75 | area= all | maxDets=100 ] = 0.000 train_yolox_container | Average Precision (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000 train_yolox_container | Average Precision (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000 train_yolox_container | Average Precision (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000 train_yolox_container | Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 1 ] = 0.000 train_yolox_container | Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 10 ] = 0.000 train_yolox_container | Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.000 train_yolox_container | Average Recall (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000 train_yolox_container | Average Recall (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000 train_yolox_container | Average Recall (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000 Convert yolox pytorch model into tensorrt model. \u2693\ufe0e Requirement \u2693\ufe0e docker docker-compose nvidia-docker2 nvidia-gpu (hardware) cd docker/torch2trt sh convert.sh Output should be like below. docker-compose build Building torch2trt Step 1/12 : FROM nvcr.io/nvidia/pytorch:22.07-py3 ---> 74d53f84c686 Step 2/12 : RUN python3 -m pip install nvidia-pyindex packaging && python3 -m pip install --upgrade nvidia-tensorrt ---> Using cache ---> 8d655c414dd2 Step 3/12 : RUN apt-get update && apt-get install -y git libgl1-mesa-dev && apt-get -y clean && rm -rf /var/lib/apt/lists/* ---> Using cache ---> 76bc393f04d5 Step 4/12 : WORKDIR / ---> Using cache ---> 47b28fa00606 Step 5/12 : RUN git clone https://github.com/NVIDIA-AI-IOT/torch2trt.git ---> Using cache ---> 1a4063050362 Step 6/12 : WORKDIR /torch2trt ---> Using cache ---> 6e679ba630a9 Step 7/12 : RUN python3 setup.py install --plugins ---> Using cache ---> f0f7dc347d9d Step 8/12 : WORKDIR / ---> Using cache ---> 1d4ffaaae9a0 Step 9/12 : RUN git clone https://github.com/Megvii-BaseDetection/YOLOX.git ---> Using cache ---> 6cc15f5a7b36 Step 10/12 : WORKDIR /YOLOX ---> Using cache ---> 3429678d2547 Step 11/12 : RUN python3 -m pip install -r requirements.txt && python3 setup.py develop ---> Using cache ---> 377ef892e986 Step 12/12 : RUN mkdir model ---> Using cache ---> 55caa4a2787d Successfully built 55caa4a2787d Successfully tagged torch2trt_torch2trt:latest docker-compose up Recreating torch2trt_torch2trt_1 ... done Attaching to torch2trt_torch2trt_1 torch2trt_1 | torch2trt_1 | ============= torch2trt_1 | == PyTorch == torch2trt_1 | ============= torch2trt_1 | torch2trt_1 | NVIDIA Release 21.09 (build 26760254) torch2trt_1 | PyTorch Version 1.10.0a0+3fd9dcf torch2trt_1 | torch2trt_1 | Container image Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved. torch2trt_1 | torch2trt_1 | Copyright (c) 2014-2021 Facebook Inc. torch2trt_1 | Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert) torch2trt_1 | Copyright (c) 2012-2014 Deepmind Technologies (Koray Kavukcuoglu) torch2trt_1 | Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu) torch2trt_1 | Copyright (c) 2011-2013 NYU (Clement Farabet) torch2trt_1 | Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston) torch2trt_1 | Copyright (c) 2006 Idiap Research Institute (Samy Bengio) torch2trt_1 | Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz) torch2trt_1 | Copyright (c) 2015 Google Inc. torch2trt_1 | Copyright (c) 2015 Yangqing Jia torch2trt_1 | Copyright (c) 2013-2016 The Caffe contributors torch2trt_1 | All rights reserved. torch2trt_1 | torch2trt_1 | NVIDIA Deep Learning Profiler (dlprof) Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved. torch2trt_1 | torch2trt_1 | Various files include modifications (c) NVIDIA CORPORATION. All rights reserved. torch2trt_1 | torch2trt_1 | This container image and its contents are governed by the NVIDIA Deep Learning Container License. torch2trt_1 | By pulling and using the container, you accept the terms and conditions of this license: torch2trt_1 | https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license torch2trt_1 | torch2trt_1 | NOTE: MOFED driver for multi-node communication was not detected. torch2trt_1 | Multi-node communication performance may be reduced. torch2trt_1 | torch2trt_1 | NOTE: The SHMEM allocation limit is set to the default of 64MB. This may be torch2trt_1 | insufficient for PyTorch. NVIDIA recommends the use of the following flags: torch2trt_1 | nvidia-docker run --ipc=host ... torch2trt_1 | torch2trt_1 | 2022-02-26 09:33:11.827 | INFO | __main__:main:57 - loaded checkpoint done. torch2trt_1 | [02/26/2022-09:33:13] [TRT] [I] [MemUsageChange] Init CUDA: CPU +188, GPU +0, now: CPU 1383, GPU 2123 (MiB) torch2trt_1 | [02/26/2022-09:33:13] [TRT] [I] [MemUsageSnapshot] Begin constructing builder kernel library: CPU 1403 MiB, GPU 2123 MiB torch2trt_1 | [02/26/2022-09:33:13] [TRT] [I] [MemUsageSnapshot] End constructing builder kernel library: CPU 1410 MiB, GPU 2123 MiB torch2trt_1 | [02/26/2022-09:33:14] [TRT] [W] Tensor DataType is determined at build time for tensors not marked as input or output. torch2trt_1 | [02/26/2022-09:33:14] [TRT] [W] FP16 support requested on hardware without native FP16 support, performance will be negatively affected. torch2trt_1 | [02/26/2022-09:33:15] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2107, GPU 2409 (MiB) torch2trt_1 | [02/26/2022-09:33:15] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2107, GPU 2417 (MiB) torch2trt_1 | [02/26/2022-09:33:15] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored. torch2trt_1 | [02/26/2022-09:33:48] [TRT] [I] Detected 1 inputs and 1 output network tensors. torch2trt_1 | [02/26/2022-09:33:48] [TRT] [I] Total Host Persistent Memory: 208144 torch2trt_1 | [02/26/2022-09:33:48] [TRT] [I] Total Device Persistent Memory: 640512 torch2trt_1 | [02/26/2022-09:33:48] [TRT] [I] Total Scratch Memory: 512 torch2trt_1 | [02/26/2022-09:33:48] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 4 MiB, GPU 294 MiB torch2trt_1 | [02/26/2022-09:33:48] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 43.9912ms to assign 7 blocks to 214 nodes requiring 7181828 bytes. torch2trt_1 | [02/26/2022-09:33:48] [TRT] [I] Total Activation Memory: 7181828 torch2trt_1 | [02/26/2022-09:33:48] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +10, now: CPU 2129, GPU 2477 (MiB) torch2trt_1 | [02/26/2022-09:33:48] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +3, GPU +4, now: CPU 3, GPU 4 (MiB) torch2trt_1 | [02/26/2022-09:33:48] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2128, GPU 2461 (MiB) torch2trt_1 | [02/26/2022-09:33:48] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +8, now: CPU 3, GPU 12 (MiB) torch2trt_1 | 2022-02-26 09:33:48.565 | INFO | __main__:main:71 - Converted TensorRT model done. torch2trt_1 | 2022-02-26 09:33:48.581 | INFO | __main__:main:79 - Converted TensorRT model engine file is saved for C++ inference. torch2trt_torch2trt_1 exited with code 0 Download dataset \u2693\ufe0e you can download dataset via google drive by running this command. ansible-playbook -i ansible/hosts/localhost.ini ansible/setup_dataset.yml --connection local --ask-become-pass","title":"Tools"},{"location":"tools/tools/#tools","text":"","title":"Tools"},{"location":"tools/tools/#train-yolox-model","text":"","title":"Train yolox model"},{"location":"tools/tools/#requirement","text":"docker docker-compose nvidia-docker2 nvidia-gpu (hardware) cd docker/train_yolox/checkpoints wget https://github.com/Megvii-BaseDetection/YOLOX/releases/download/0.1.1rc0/yolox_s.pth cd ../datasets download datasets via this link . docker-compose up --build While training, you can see output like below. 100%|##########| 1/1 [00:00<00:00, 4.69it/s] train_yolox_container | Running per image evaluation... train_yolox_container | Evaluate annotation type *bbox* train_yolox_container | COCOeval_opt.evaluate() finished in 0.01 seconds. train_yolox_container | Accumulating evaluation results... train_yolox_container | 2022-06-03 04:51:11 | INFO | pycocotools.coco:366 - index created! train_yolox_container | 2022-06-03 04:51:11 | INFO | yolox.core.trainer:342 - train_yolox_container | Average forward time: 0.00 ms, Average NMS time: 0.00 ms, Average inference time: 0.00 ms train_yolox_container | Average Precision (AP) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.000 train_yolox_container | Average Precision (AP) @[ IoU=0.50 | area= all | maxDets=100 ] = 0.000 train_yolox_container | Average Precision (AP) @[ IoU=0.75 | area= all | maxDets=100 ] = 0.000 train_yolox_container | Average Precision (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000 train_yolox_container | Average Precision (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000 train_yolox_container | Average Precision (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000 train_yolox_container | Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 1 ] = 0.000 train_yolox_container | Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 10 ] = 0.000 train_yolox_container | Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.000 train_yolox_container | Average Recall (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000 train_yolox_container | Average Recall (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000 train_yolox_container | Average Recall (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000 train_yolox_container | train_yolox_container | 2022-06-03 04:51:11 | INFO | yolox.core.trainer:352 - Save weights to ./YOLOX_outputs/yolox_s train_yolox_container | 2022-06-03 04:51:11 | INFO | yolox.core.trainer:352 - Save weights to ./YOLOX_outputs/yolox_s train_yolox_container | 2022-06-03 04:51:12 | INFO | yolox.core.trainer:203 - ---> start train epoch272 train_yolox_container | 2022-06-03 04:51:15 | INFO | yolox.core.trainer:352 - Save weights to ./YOLOX_outputs/yolox_s train_yolox_container | 2022-06-03 04:51:15 | INFO | yolox.evaluators.coco_evaluator:235 - Evaluate in main process... train_yolox_container | 2022-06-03 04:51:15 | INFO | yolox.evaluators.coco_evaluator:268 - Loading and preparing results... train_yolox_container | 2022-06-03 04:51:15 | INFO | yolox.evaluators.coco_evaluator:268 - DONE (t=0.00s) train_yolox_container | 2022-06-03 04:51:15 | INFO | pycocotools.coco:366 - creating index... train_yolox_container | 2022-06-03 04:51:15 | INFO | pycocotools.coco:366 - index created! train_yolox_container | 2022-06-03 04:51:16 | INFO | yolox.core.trainer:342 - train_yolox_container | Average forward time: 0.00 ms, Average NMS time: 0.00 ms, Average inference time: 0.00 ms train_yolox_container | Average Precision (AP) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.000 train_yolox_container | Average Precision (AP) @[ IoU=0.50 | area= all | maxDets=100 ] = 0.000 train_yolox_container | Average Precision (AP) @[ IoU=0.75 | area= all | maxDets=100 ] = 0.000 train_yolox_container | Average Precision (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000 train_yolox_container | Average Precision (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000 train_yolox_container | Average Precision (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000 train_yolox_container | Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 1 ] = 0.000 train_yolox_container | Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 10 ] = 0.000 train_yolox_container | Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.000 train_yolox_container | Average Recall (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000 train_yolox_container | Average Recall (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000 train_yolox_container | Average Recall (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000","title":"Requirement"},{"location":"tools/tools/#convert-yolox-pytorch-model-into-tensorrt-model","text":"","title":"Convert yolox pytorch model into tensorrt model."},{"location":"tools/tools/#requirement_1","text":"docker docker-compose nvidia-docker2 nvidia-gpu (hardware) cd docker/torch2trt sh convert.sh Output should be like below. docker-compose build Building torch2trt Step 1/12 : FROM nvcr.io/nvidia/pytorch:22.07-py3 ---> 74d53f84c686 Step 2/12 : RUN python3 -m pip install nvidia-pyindex packaging && python3 -m pip install --upgrade nvidia-tensorrt ---> Using cache ---> 8d655c414dd2 Step 3/12 : RUN apt-get update && apt-get install -y git libgl1-mesa-dev && apt-get -y clean && rm -rf /var/lib/apt/lists/* ---> Using cache ---> 76bc393f04d5 Step 4/12 : WORKDIR / ---> Using cache ---> 47b28fa00606 Step 5/12 : RUN git clone https://github.com/NVIDIA-AI-IOT/torch2trt.git ---> Using cache ---> 1a4063050362 Step 6/12 : WORKDIR /torch2trt ---> Using cache ---> 6e679ba630a9 Step 7/12 : RUN python3 setup.py install --plugins ---> Using cache ---> f0f7dc347d9d Step 8/12 : WORKDIR / ---> Using cache ---> 1d4ffaaae9a0 Step 9/12 : RUN git clone https://github.com/Megvii-BaseDetection/YOLOX.git ---> Using cache ---> 6cc15f5a7b36 Step 10/12 : WORKDIR /YOLOX ---> Using cache ---> 3429678d2547 Step 11/12 : RUN python3 -m pip install -r requirements.txt && python3 setup.py develop ---> Using cache ---> 377ef892e986 Step 12/12 : RUN mkdir model ---> Using cache ---> 55caa4a2787d Successfully built 55caa4a2787d Successfully tagged torch2trt_torch2trt:latest docker-compose up Recreating torch2trt_torch2trt_1 ... done Attaching to torch2trt_torch2trt_1 torch2trt_1 | torch2trt_1 | ============= torch2trt_1 | == PyTorch == torch2trt_1 | ============= torch2trt_1 | torch2trt_1 | NVIDIA Release 21.09 (build 26760254) torch2trt_1 | PyTorch Version 1.10.0a0+3fd9dcf torch2trt_1 | torch2trt_1 | Container image Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved. torch2trt_1 | torch2trt_1 | Copyright (c) 2014-2021 Facebook Inc. torch2trt_1 | Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert) torch2trt_1 | Copyright (c) 2012-2014 Deepmind Technologies (Koray Kavukcuoglu) torch2trt_1 | Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu) torch2trt_1 | Copyright (c) 2011-2013 NYU (Clement Farabet) torch2trt_1 | Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston) torch2trt_1 | Copyright (c) 2006 Idiap Research Institute (Samy Bengio) torch2trt_1 | Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz) torch2trt_1 | Copyright (c) 2015 Google Inc. torch2trt_1 | Copyright (c) 2015 Yangqing Jia torch2trt_1 | Copyright (c) 2013-2016 The Caffe contributors torch2trt_1 | All rights reserved. torch2trt_1 | torch2trt_1 | NVIDIA Deep Learning Profiler (dlprof) Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved. torch2trt_1 | torch2trt_1 | Various files include modifications (c) NVIDIA CORPORATION. All rights reserved. torch2trt_1 | torch2trt_1 | This container image and its contents are governed by the NVIDIA Deep Learning Container License. torch2trt_1 | By pulling and using the container, you accept the terms and conditions of this license: torch2trt_1 | https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license torch2trt_1 | torch2trt_1 | NOTE: MOFED driver for multi-node communication was not detected. torch2trt_1 | Multi-node communication performance may be reduced. torch2trt_1 | torch2trt_1 | NOTE: The SHMEM allocation limit is set to the default of 64MB. This may be torch2trt_1 | insufficient for PyTorch. NVIDIA recommends the use of the following flags: torch2trt_1 | nvidia-docker run --ipc=host ... torch2trt_1 | torch2trt_1 | 2022-02-26 09:33:11.827 | INFO | __main__:main:57 - loaded checkpoint done. torch2trt_1 | [02/26/2022-09:33:13] [TRT] [I] [MemUsageChange] Init CUDA: CPU +188, GPU +0, now: CPU 1383, GPU 2123 (MiB) torch2trt_1 | [02/26/2022-09:33:13] [TRT] [I] [MemUsageSnapshot] Begin constructing builder kernel library: CPU 1403 MiB, GPU 2123 MiB torch2trt_1 | [02/26/2022-09:33:13] [TRT] [I] [MemUsageSnapshot] End constructing builder kernel library: CPU 1410 MiB, GPU 2123 MiB torch2trt_1 | [02/26/2022-09:33:14] [TRT] [W] Tensor DataType is determined at build time for tensors not marked as input or output. torch2trt_1 | [02/26/2022-09:33:14] [TRT] [W] FP16 support requested on hardware without native FP16 support, performance will be negatively affected. torch2trt_1 | [02/26/2022-09:33:15] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2107, GPU 2409 (MiB) torch2trt_1 | [02/26/2022-09:33:15] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2107, GPU 2417 (MiB) torch2trt_1 | [02/26/2022-09:33:15] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored. torch2trt_1 | [02/26/2022-09:33:48] [TRT] [I] Detected 1 inputs and 1 output network tensors. torch2trt_1 | [02/26/2022-09:33:48] [TRT] [I] Total Host Persistent Memory: 208144 torch2trt_1 | [02/26/2022-09:33:48] [TRT] [I] Total Device Persistent Memory: 640512 torch2trt_1 | [02/26/2022-09:33:48] [TRT] [I] Total Scratch Memory: 512 torch2trt_1 | [02/26/2022-09:33:48] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 4 MiB, GPU 294 MiB torch2trt_1 | [02/26/2022-09:33:48] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 43.9912ms to assign 7 blocks to 214 nodes requiring 7181828 bytes. torch2trt_1 | [02/26/2022-09:33:48] [TRT] [I] Total Activation Memory: 7181828 torch2trt_1 | [02/26/2022-09:33:48] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +10, now: CPU 2129, GPU 2477 (MiB) torch2trt_1 | [02/26/2022-09:33:48] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +3, GPU +4, now: CPU 3, GPU 4 (MiB) torch2trt_1 | [02/26/2022-09:33:48] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2128, GPU 2461 (MiB) torch2trt_1 | [02/26/2022-09:33:48] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +8, now: CPU 3, GPU 12 (MiB) torch2trt_1 | 2022-02-26 09:33:48.565 | INFO | __main__:main:71 - Converted TensorRT model done. torch2trt_1 | 2022-02-26 09:33:48.581 | INFO | __main__:main:79 - Converted TensorRT model engine file is saved for C++ inference. torch2trt_torch2trt_1 exited with code 0","title":"Requirement"},{"location":"tools/tools/#download-dataset","text":"you can download dataset via google drive by running this command. ansible-playbook -i ansible/hosts/localhost.ini ansible/setup_dataset.yml --connection local --ask-become-pass","title":"Download dataset"},{"location":"tutorials/build_instraction/","text":"Build Instractions \u2693\ufe0e If you want to know about supported platfroms, please see also this page . setup develop environment (full package) \u2693\ufe0e first time sh setup.sh not first time (skip installing ros2) sh update.sh setup develop container \u2693\ufe0e docker compose build docker compose up -d ansible-playbook -i ansible/hosts/docker.ini ansible/setup_dev_environment.yml Troubleshooting \u2693\ufe0e Failed to connect to the host via ssh Please execute command below to delete fingerprint of localhost:2022 ssh-keygen -f \"${HOME}/.ssh/known_hosts\" -R \"[localhost]:2022\" setup real robot \u2693\ufe0e <span style=\"color: red; \"> NOTE : setting up real robot is fully automated via github actions, so using this setup-robot playbook manually is not recommended. These operations should be run in robot. setup endpoint sh ansible/setup_ansible.sh export PERSONAL_ACCESS_TOKEN=$(ACCESS_TOKEN_OF_WAM_V_TAN_BOT) ansible-playbook -i ansible/hosts/localhost.ini ansible/setup_endpoint.yml --connection local --ask-become-pass If you want to know personal access token, please read this documentation . setup firmware development environment \u2693\ufe0e This playbook includes three steps. 1. Install Docker 1. Clone firmware package 1. Build firmware with docker ansible-playbook -i ansible/hosts/localhost.ini ansible/setup_mbed_workspace.yml --connection local --ask-become-pass","title":"Build Instractions"},{"location":"tutorials/build_instraction/#build-instractions","text":"If you want to know about supported platfroms, please see also this page .","title":"Build Instractions"},{"location":"tutorials/build_instraction/#setup-develop-environment-full-package","text":"first time sh setup.sh not first time (skip installing ros2) sh update.sh","title":"setup develop environment (full package)"},{"location":"tutorials/build_instraction/#setup-develop-container","text":"docker compose build docker compose up -d ansible-playbook -i ansible/hosts/docker.ini ansible/setup_dev_environment.yml","title":"setup develop container"},{"location":"tutorials/build_instraction/#troubleshooting","text":"Failed to connect to the host via ssh Please execute command below to delete fingerprint of localhost:2022 ssh-keygen -f \"${HOME}/.ssh/known_hosts\" -R \"[localhost]:2022\"","title":"Troubleshooting"},{"location":"tutorials/build_instraction/#setup-real-robot","text":"<span style=\"color: red; \"> NOTE : setting up real robot is fully automated via github actions, so using this setup-robot playbook manually is not recommended. These operations should be run in robot. setup endpoint sh ansible/setup_ansible.sh export PERSONAL_ACCESS_TOKEN=$(ACCESS_TOKEN_OF_WAM_V_TAN_BOT) ansible-playbook -i ansible/hosts/localhost.ini ansible/setup_endpoint.yml --connection local --ask-become-pass If you want to know personal access token, please read this documentation .","title":"setup real robot"},{"location":"tutorials/build_instraction/#setup-firmware-development-environment","text":"This playbook includes three steps. 1. Install Docker 1. Clone firmware package 1. Build firmware with docker ansible-playbook -i ansible/hosts/localhost.ini ansible/setup_mbed_workspace.yml --connection local --ask-become-pass","title":"setup firmware development environment"},{"location":"tutorials/ml_pipeline/","text":"ML Pipeline \u2693\ufe0e What we can do? \u2693\ufe0e We can train / convert yolox model automatically. Install \u2693\ufe0e ansible-galaxy install -fr ansible/roles/requirements.yml ansible-playbook -i ansible/hosts/localhost.ini ansible/setup_ml_pipeline.yml --connection local --ask-become-pass","title":"ML Pipeline"},{"location":"tutorials/ml_pipeline/#ml-pipeline","text":"","title":"ML Pipeline"},{"location":"tutorials/ml_pipeline/#what-we-can-do","text":"We can train / convert yolox model automatically.","title":"What we can do?"},{"location":"tutorials/ml_pipeline/#install","text":"ansible-galaxy install -fr ansible/roles/requirements.yml ansible-playbook -i ansible/hosts/localhost.ini ansible/setup_ml_pipeline.yml --connection local --ask-become-pass","title":"Install"},{"location":"tutorials/navigation_demo/","text":"Navigation Demo \u2693\ufe0e How to run demo \u2693\ufe0e build packages \u2693\ufe0e Please see also, this page . run simulator and planner \u2693\ufe0e ros2 launch navi_sim with_planner.launch.py set goal \u2693\ufe0e use 2d goal pose tool in rviz. then, the navigation starts. spawn obstacle \u2693\ufe0e use clicked point tool in rviz then, replan waypoints.","title":"Navigation Demo"},{"location":"tutorials/navigation_demo/#navigation-demo","text":"","title":"Navigation Demo"},{"location":"tutorials/navigation_demo/#how-to-run-demo","text":"","title":"How to run demo"},{"location":"tutorials/navigation_demo/#build-packages","text":"Please see also, this page .","title":"build packages"},{"location":"tutorials/navigation_demo/#run-simulator-and-planner","text":"ros2 launch navi_sim with_planner.launch.py","title":"run simulator and planner"},{"location":"tutorials/navigation_demo/#set-goal","text":"use 2d goal pose tool in rviz. then, the navigation starts.","title":"set goal"},{"location":"tutorials/navigation_demo/#spawn-obstacle","text":"use clicked point tool in rviz then, replan waypoints.","title":"spawn obstacle"},{"location":"tutorials/supported_platforms/","text":"Supported Platform \u2693\ufe0e ubuntu 20.04 \u2693\ufe0e If your ubuntu version is older than 20.04, you can use docker environment. ansible task install ROS2 foxy, so you do not necessary to setup ROS2 before you run ansible-script, you have to install ansible via apt sudo apt install ansible","title":"Supported Platform"},{"location":"tutorials/supported_platforms/#supported-platform","text":"","title":"Supported Platform"},{"location":"tutorials/supported_platforms/#ubuntu-2004","text":"If your ubuntu version is older than 20.04, you can use docker environment. ansible task install ROS2 foxy, so you do not necessary to setup ROS2 before you run ansible-script, you have to install ansible via apt sudo apt install ansible","title":"ubuntu 20.04"}]}